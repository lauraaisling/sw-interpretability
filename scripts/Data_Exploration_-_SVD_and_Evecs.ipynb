{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ba241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts/')\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.axes as axes\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "sns.set_style(\"darkgrid\")\n",
    "from PIL import Image\n",
    "import random # random seed to reproduce MDS and t-SNE plots\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import cluster # k-Means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import manifold # MDS and t-SNE\n",
    "from sklearn.metrics import silhouette_score # silhouette width for clustering\n",
    "from sklearn import preprocessing # scaling attributes\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import hdbscan\n",
    "import umap\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from lucent.optvis import render, param, transform, objectives\n",
    "\n",
    "import imp\n",
    "import my_datasets\n",
    "import utilities \n",
    "imp.reload(my_datasets) \n",
    "imp.reload(utilities) \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset='ilsvrc12fine'\n",
    "dataset='ilsvrc12'\n",
    "paths, count, y, idx_to_labels = my_datasets.get_dataset(dataset)\n",
    "\n",
    "print(count, len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16938371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ilsvrc12fine dataset, paths are mapped differently\n",
    "if dataset=='ilsvrc12fine':\n",
    "    idxs=np.arange(0, 1281167, 10) \n",
    "    classes=np.unique(y[idxs])\n",
    "    ppaths=[paths[i] for i in idxs]\n",
    "    paths=ppaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer='Mixed_7b.cat_2'\n",
    "SAVEFOLD0=f'../outputs/{dataset}'\n",
    "SAVEFOLD=f\"{SAVEFOLD0}/{layer}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradients_wrt_conv_layer=np.load(f\"{SAVEFOLD}/gradients_wrt_conv_layer.npy\")\n",
    "predictions=np.load(f\"{SAVEFOLD}/predictions.npy\", mmap_mode = 'r')\n",
    "conv_maps=np.load(f\"{SAVEFOLD}/conv_maps.npy\", mmap_mode = 'r')\n",
    "\n",
    "# pvh=np.load(f\"{SAVEFOLD}/eigenvectors.npy\",allow_pickle=True, mmap_mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_maps_avg = conv_maps.mean(3).mean(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e1f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pu, ps, pvh = np.linalg.svd(conv_maps_avg)\n",
    "\n",
    "# np.save(f\"{SAVEFOLD}/pu.npy\", pu)\n",
    "# np.save(f\"{SAVEFOLD}/ps.npy\", ps)\n",
    "# np.save(f\"{SAVEFOLD}/eigenvectors.npy\", pvh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvh = np.load(f'{SAVEFOLD}/eigenvectors.npy')\n",
    "pu = np.load(f'{SAVEFOLD}/pu.npy')\n",
    "ps = np.load(f'{SAVEFOLD}/ps.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = None # None / \"standardise\" / \"normalise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "normalise = MinMaxScaler()\n",
    "\n",
    "standardised_data = scale.fit_transform(conv_maps_avg) \n",
    "normalised_data = normalise.fit_transform(conv_maps_avg) # .shape (10000, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transforms == \"standardise\":\n",
    "    activations = standardised_data\n",
    "    print(\"Standardise\")\n",
    "elif transforms == \"normalise\": \n",
    "    activations = normalised_data\n",
    "    print(\"Normalise\")\n",
    "else: \n",
    "    activations = conv_maps_avg\n",
    "    print(\"Raw activations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3845e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610724f",
   "metadata": {},
   "source": [
    "Evec maximally projecting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629bc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dirs = 20\n",
    "top=50\n",
    "evecs_dot = np.empty([len(conv_maps_avg),num_dirs])\n",
    "evecs_sim = np.empty([len(conv_maps_avg),num_dirs])\n",
    "for i in range(len(conv_maps_avg)):\n",
    "    for direction in range(num_dirs):\n",
    "        evecs_dot[i,direction] = np.dot(conv_maps_avg[i], pvh[direction])\n",
    "        evecs_sim[i,direction] = evecs_dot[i,direction]/(np.linalg.norm(conv_maps_avg[i])*np.linalg.norm(conv_maps_avg[direction]))\n",
    "\n",
    "top_evec_projs = []\n",
    "for direction in range(len(evecs_dot[0,])):\n",
    "    top_evec_projs.append(evecs_dot[:,direction].argsort()[-top:][::-1])\n",
    "    \n",
    "for direction in range(num_dirs):\n",
    "    evec_projs_f = f\"{SAVEFOLD}/analysis/evec_max_projs_{direction}.png\"\n",
    "    if not os.path.exists(evec_projs_f):\n",
    "        fig, ax = plt.subplots(math.ceil(top//5), 5, figsize = (10,20))\n",
    "        ax = ax.flatten()\n",
    "        for idx, im_id in enumerate(top_evec_projs[direction]):# enumerate(concepts_dot[:,concept].argsort()[-top:][::-1]):\n",
    "            im = Image.open(paths[im_id])\n",
    "            ax[idx].imshow(im)\n",
    "            ax[idx].set_title(f\"{im_id}\", size = 8)\n",
    "            ax[idx].axis('off')\n",
    "        fig.savefig(evec_projs_f, bbox_inches=\"tight\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2abae7",
   "metadata": {},
   "source": [
    "UMAP of evec to projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e227075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image collection params\n",
    "direction = 0\n",
    "top = 50\n",
    "\n",
    "# clustering params\n",
    "linkage='ward'\n",
    "metric='euclidean'\n",
    "distance_threshold = 12\n",
    "\n",
    "kmeans_outlier_threshold = 15\n",
    "min_ims_cluster = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75763a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this case direction is evec direction\n",
    "evec_dot = np.empty([len(conv_maps_avg)])\n",
    "evec_sim = np.empty([len(conv_maps_avg)])\n",
    "for i in range(len(conv_maps_avg)):\n",
    "    evec_dot[i] = np.dot(conv_maps_avg[i], pvh[direction])\n",
    "    evec_sim[i] = evec_dot[i]/(np.linalg.norm(conv_maps_avg[i])*np.linalg.norm(conv_maps_avg[direction]))\n",
    "\n",
    "top_ims = evec_dot.argsort()[-top:][::-1]\n",
    "top_activations = utilities.get_activations(activations_avg = activations, ims=top_ims)\n",
    "    \n",
    "fig, ax = plt.subplots(math.ceil(top//5), 5, figsize = (10,20))\n",
    "ax = ax.flatten()\n",
    "for idx, im_id in enumerate(top_ims):# enumerate(concepts_dot[:,concept].argsort()[-top:][::-1]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    ax[idx].imshow(im)\n",
    "    ax[idx].set_title(f\"{im_id}\", size = 8)\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "evec_UMAP_f = f\"{SAVEFOLD}/analysis/evec_UMAP_{direction}.png\"\n",
    "XY_UMAP = umap.UMAP(n_components=2).fit_transform(top_activations)\n",
    "amount = .1\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "#ax.set_title(\"UMAP\")\n",
    "ax.scatter(XY_UMAP[:,0], XY_UMAP[:,1]) \n",
    "\n",
    "for x0, y0, path in zip(utilities.rand_jitter(XY_UMAP[:,0], amount), utilities.rand_jitter(XY_UMAP[:,1], amount), [paths[i] for i in top_ims]):\n",
    "    ab = AnnotationBbox(utilities.getImage(path, zoom = 0.1), (x0, y0), frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "#ax.axis('off') \n",
    "fig.savefig(evec_UMAP_f, bbox_inches=\"tight\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c6ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
