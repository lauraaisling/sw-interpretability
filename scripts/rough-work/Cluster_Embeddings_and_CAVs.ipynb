{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2a0aa5",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts/')\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.axes as axes\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "sns.set_style(\"darkgrid\")\n",
    "from PIL import Image\n",
    "import random # random seed to reproduce MDS and t-SNE plots\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import cluster # k-Means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import manifold # MDS and t-SNE\n",
    "from sklearn.metrics import silhouette_score # silhouette width for clustering\n",
    "from sklearn import preprocessing # scaling attributes\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import hdbscan\n",
    "import umap\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# from captum.concept import TCAV\n",
    "# from captum.concept import Concept\n",
    "# from captum.concept._utils.data_iterator import dataset_to_dataloader, CustomIterableDataset\n",
    "# from captum.concept._utils.common import concepts_to_str\n",
    "\n",
    "from lucent.optvis import render, param, transform, objectives\n",
    "\n",
    "import imp\n",
    "import my_datasets\n",
    "import utilities \n",
    "imp.reload(my_datasets) \n",
    "imp.reload(utilities) \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e787e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset='ilsvrc12fine'\n",
    "paths, count, y, idx_to_labels = my_datasets.get_dataset(dataset)\n",
    "\n",
    "print(count, len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7613e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ilsvrc12fine dataset, paths are mapped differently\n",
    "if dataset=='ilsvrc12fine':\n",
    "    idxs=np.arange(0, 1281167, 10) \n",
    "    classes=np.unique(y[idxs])\n",
    "    ppaths=[paths[i] for i in idxs]\n",
    "    paths=ppaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer='Mixed_7b.cat_2'\n",
    "SAVEFOLD0=f'../outputs/{dataset}'\n",
    "SAVEFOLD=f\"{SAVEFOLD0}/{layer}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradients_wrt_conv_layer=np.load(f\"{SAVEFOLD}/gradients_wrt_conv_layer.npy\")\n",
    "predictions=np.load(f\"{SAVEFOLD}/predictions.npy\", mmap_mode = 'r')\n",
    "conv_maps=np.load(f\"{SAVEFOLD}/conv_maps.npy\", mmap_mode = 'r')\n",
    "\n",
    "# pvh=np.load(f\"{SAVEFOLD}/eigenvectors.npy\",allow_pickle=True, mmap_mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_maps_avg = conv_maps.mean(3).mean(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf189594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pu, ps, pvh = np.linalg.svd(conv_maps_avg)\n",
    "\n",
    "# np.save(f\"{SAVEFOLD}/pu.npy\", pu)\n",
    "# np.save(f\"{SAVEFOLD}/ps.npy\", ps)\n",
    "# np.save(f\"{SAVEFOLD}/eigenvectors.npy\", pvh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvh = np.load(f'{SAVEFOLD}/eigenvectors.npy')\n",
    "pu = np.load(f'{SAVEFOLD}/pu.npy')\n",
    "ps = np.load(f'{SAVEFOLD}/ps.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0167941",
   "metadata": {},
   "source": [
    "Are we standardising or normalising the activations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = None # None / \"standardise\" / \"normalise\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697b210",
   "metadata": {},
   "source": [
    "Global average pooling of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "normalise = MinMaxScaler()\n",
    "\n",
    "standardised_data = scale.fit_transform(conv_maps_avg) \n",
    "normalised_data = normalise.fit_transform(conv_maps_avg) # .shape (10000, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transforms == \"standardise\":\n",
    "    activations = standardised_data\n",
    "    print(\"Standardise\")\n",
    "elif transforms == \"normalise\": \n",
    "    activations = normalised_data\n",
    "    print(\"Normalise\")\n",
    "else: \n",
    "    activations = conv_maps_avg\n",
    "    print(\"Raw activations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8116d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# conv_maps_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3aa408",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f8261",
   "metadata": {},
   "source": [
    "## Random analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae62dd4",
   "metadata": {},
   "source": [
    "Evec maximally projecting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44cc8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_dirs = 10\n",
    "# top=50\n",
    "# evecs_dot = np.empty([len(conv_maps_avg),num_dirs])\n",
    "# evecs_sim = np.empty([len(conv_maps_avg),num_dirs])\n",
    "# for i in range(len(conv_maps_avg)):\n",
    "#     for direction in range(num_dirs):\n",
    "#         evecs_dot[i,direction] = np.dot(conv_maps_avg[i], pvh[direction])\n",
    "#         evecs_sim[i,direction] = evecs_dot[i,direction]/(np.linalg.norm(conv_maps_avg[i])*np.linalg.norm(conv_maps_avg[direction]))\n",
    "\n",
    "# top_evec_projs = []\n",
    "# for direction in range(len(evecs_dot[0,])):\n",
    "#     top_evec_projs.append(evecs_dot[:,direction].argsort()[-top:][::-1])\n",
    "    \n",
    "# for direction in range(num_dirs):\n",
    "#     fig, ax = plt.subplots(math.ceil(top//5), 5, figsize = (10,20))\n",
    "#     ax = ax.flatten()\n",
    "#     for idx, im_id in enumerate(top_evec_projs[direction]):# enumerate(concepts_dot[:,concept].argsort()[-top:][::-1]):\n",
    "#         im = Image.open(paths[im_id])\n",
    "#         ax[idx].imshow(im)\n",
    "#         ax[idx].set_title(f\"{im_id}\", size = 8)\n",
    "#         ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efd431",
   "metadata": {},
   "source": [
    "Analyse sample of random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dafb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342f6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991ff61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top=100\n",
    "rand_ims = []\n",
    "for i in range(top):\n",
    "    rand_ims.append(random.randint(0, len(paths)))\n",
    "rand_ims = np.array(rand_ims)\n",
    "rand_ims\n",
    "rand_activations = utilities.get_activations(activations_avg = activations, ims=rand_ims)\n",
    "\n",
    "clusterer_rand = AgglomerativeClustering(n_clusters=None, distance_threshold=0, metric=metric,linkage=linkage )\n",
    "clusterer_rand.fit_predict(rand_activations)\n",
    "\n",
    "linkage_res = utilities.plot_dendrogram(clusterer_rand, truncate_mode=\"level\") # , p=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc7fe2",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f49cc",
   "metadata": {},
   "source": [
    "Neurons:\n",
    "\n",
    "1 underwater, scuba diving\n",
    "\n",
    "5 peacock/police van\n",
    "\n",
    "13 black background, clusters for performing\n",
    "\n",
    "16 oval / lobster\n",
    "\n",
    "18 snake, coral\n",
    "\n",
    "25 writing sticking out and print\n",
    "\n",
    "27 fluffy cream dog, book shelves\n",
    "\n",
    "22 toilet roll, brown dog face\n",
    "\n",
    "35 sport/green apple\n",
    "\n",
    "57 black dog, diagonal rod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebe992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image collection params\n",
    "direction = 22\n",
    "top = 100\n",
    "\n",
    "# clustering params\n",
    "linkage='ward'\n",
    "metric='euclidean'\n",
    "distance_threshold = 15\n",
    "\n",
    "kmeans_outlier_threshold = 15\n",
    "min_ims_cluster = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(clusterer_rand.distances_)\n",
    "# _ = utilities.plot_euclidan_distances(rand_activations, label = 'random images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d75ddf",
   "metadata": {},
   "source": [
    "# Step 1: Calculate top images and extract activations for selected neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check clustering random images\n",
    "# top_ims = []\n",
    "# for i in range(top):\n",
    "#     top_ims.append(random.randint(0, len(paths)))\n",
    "# top_ims = np.array(top_ims)\n",
    "# top_ims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4458365c",
   "metadata": {},
   "source": [
    "#### If looking at neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597da713",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ims = utilities.get_activations(activations_avg = activations, direction = direction).argsort()[-top:][::-1] \n",
    "top_activations = utilities.get_activations(activations_avg = activations, ims=top_ims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c883d",
   "metadata": {},
   "source": [
    "#### If looking at evec direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d079513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in this case direction is evec direction\n",
    "# evec_dot = np.empty([len(conv_maps_avg)])\n",
    "# evec_sim = np.empty([len(conv_maps_avg)])\n",
    "# for i in range(len(conv_maps_avg)):\n",
    "#     evec_dot[i] = np.dot(conv_maps_avg[i], pvh[direction])\n",
    "#     evec_sim[i] = evec_dot[i]/(np.linalg.norm(conv_maps_avg[i])*np.linalg.norm(conv_maps_avg[direction]))\n",
    "\n",
    "# top_ims = evec_dot.argsort()[-top:][::-1]\n",
    "# top_activations = utilities.get_activations(activations_avg = activations, ims=top_ims)\n",
    "    \n",
    "# fig, ax = plt.subplots(math.ceil(top//5), 5, figsize = (10,20))\n",
    "# ax = ax.flatten()\n",
    "# for idx, im_id in enumerate(top_ims):# enumerate(concepts_dot[:,concept].argsort()[-top:][::-1]):\n",
    "#     im = Image.open(paths[im_id])\n",
    "#     ax[idx].imshow(im)\n",
    "#     ax[idx].set_title(f\"{im_id}\", size = 8)\n",
    "#     ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4290b0a",
   "metadata": {},
   "source": [
    "## Step 2: Find number of clusters using agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a08a6",
   "metadata": {},
   "source": [
    "First, just look dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e7996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusterer_0 = AgglomerativeClustering(n_clusters=None, distance_threshold=0, metric=metric,linkage=linkage )\n",
    "clusterer_0.fit_predict(top_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb7f74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linkage_res = utilities.plot_dendrogram(clusterer_0, truncate_mode=\"level\") # , p=100 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterer_0.distances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42bc5d",
   "metadata": {},
   "source": [
    "Cluster with set distance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df814f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusterer = AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold, metric=metric,linkage=linkage)\n",
    "clusterer.fit_predict(top_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688790f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#old - taking longest clean distance in dendrogram\n",
    "# max_diff = [clusterer_0.distances_[i] - clusterer_0.distances_[i-1] if i else clusterer_0.distances_[i] for i in range(len(clusterer_0.distances_))]  \n",
    "# clusterer = AgglomerativeClustering(n_clusters=None, distance_threshold=clusterer_0.distances_[np.argmax(max_diff)], metric=metric,linkage=linkage )\n",
    "\n",
    "#RW\n",
    "# clusterer = AgglomerativeClustering(n_clusters=None, distance_threshold=12, metric=metric,linkage=linkage )\n",
    "# clusterer.fit_predict(top_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3cc4d6",
   "metadata": {},
   "source": [
    "Visualise how hierarchial clustering clusters number of clusters selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99876a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_labs = clusterer.labels_\n",
    "# print(clu_labs)\n",
    "clu_lab_order = sorted(range(len(clu_labs)), key=lambda k: clu_labs[k])\n",
    "\n",
    "fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5, figsize = (10,20))\n",
    "ax = ax.flatten()\n",
    "for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    ax[idx].imshow(im)\n",
    "    ax[idx].set_title(f\"{im_id}: cluster {clu_labs[clu_lab_order][idx]}\", size = 8)\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb7797",
   "metadata": {},
   "source": [
    "## Step 3: Run kmeans with number of clusters from step 2, remove outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e108231",
   "metadata": {},
   "source": [
    "Cluster with number of clusters selected with kmeans since need centroids to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=clusterer.n_clusters_, random_state=0, n_init=5, max_iter=1000).fit(top_activations)\n",
    "# kmeans # \"auto\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf14db",
   "metadata": {},
   "source": [
    "plot kmeans clusters before removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356232ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_labs = kmeans.labels_\n",
    "# print(clu_labs)\n",
    "clu_lab_order = sorted(range(len(clu_labs)), key=lambda k: clu_labs[k])\n",
    "\n",
    "fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5, figsize = (10,20))\n",
    "ax = ax.flatten()\n",
    "for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    ax[idx].imshow(im)\n",
    "    ax[idx].set_title(f\"{im_id}: cluster {clu_labs[clu_lab_order][idx]}\", size = 8)\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed0d54",
   "metadata": {},
   "source": [
    "Visualise activations with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9b0e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XY_UMAP = umap.UMAP(n_components=2).fit_transform(top_activations)\n",
    "utilities.clustering_scatterplot(points=XY_UMAP, \n",
    "                       labels=clu_labs,\n",
    "                       centers=None, \n",
    "                       title='UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c859cea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cosine_sim = utilities.plot_cosine_similarities(top_ims, min_sim=0, max_sim=1, maps = activations, label = 'All')\n",
    "cosine_sim = utilities.plot_cosine_similarities(top_ims[clu_lab_order], min_sim=0, max_sim=1, maps = activations, label = 'Ordered')\n",
    "# for cluster in np.unique(clu_labs): \n",
    "#     cosine_sim = utilities.plot_cosine_similarities(top_ims[clu_labs==cluster], min_sim=0, max_sim=1, maps = activations, label = f'Cluster {round(cluster)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1b8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_matrix = utilities.plot_euclidan_distances(top_activations, label = 'all')\n",
    "distance_matrix = utilities.plot_euclidan_distances(top_activations[clu_lab_order], label = 'all')\n",
    "# for cluster in np.unique(clu_labs):\n",
    "#     distance_matrix = utilities.plot_euclidan_distances(top_activations[clu_labs==cluster], label = f'cluster {round(cluster)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8bc0b",
   "metadata": {},
   "source": [
    "Need to remove outliers to purify clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad71220",
   "metadata": {},
   "source": [
    "Get squared distance to kmeans centroid of appropriate cluster - transform()\n",
    "\n",
    "https://stackoverflow.com/questions/54240144/distance-between-nodes-and-the-centroid-in-a-kmeans-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edc4a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centroid_dist = kmeans.transform(top_activations)**2\n",
    "nearest_centroid_dist = np.zeros(len(clu_labs))\n",
    "nearest_centroid_dist = [centroid_dist[i,clu_labs[i]] for i in range(len(clu_labs))]\n",
    "# nearest_centroid_dist\n",
    "# kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6efcc",
   "metadata": {},
   "source": [
    "Calculate which images are outliers by removing observations far away from centroid\n",
    "\n",
    "Rename outliers to now belong to cluster label '100'. They will now be ordered at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfa46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clu_labs_rm_outliers = np.empty(len(clu_labs))\n",
    "clu_labs_rm_outliers[:] = 100\n",
    "# clu_labs_rm_outliers\n",
    "#clu_labs_rm_outliers = [centroid_dist[i,clu_labs[i]] for i in range(len(clu_labs))]\n",
    "for i in range(len(clu_labs)):\n",
    "    if nearest_centroid_dist[i] < kmeans_outlier_threshold:\n",
    "        clu_labs_rm_outliers[i] = clu_labs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcb64f",
   "metadata": {},
   "source": [
    "visualise images remaining in clusters after removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d705602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clu_labs_rm_outliers_order = sorted(range(len(clu_labs_rm_outliers)), key=lambda k: clu_labs_rm_outliers[k])\n",
    "\n",
    "# fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5, figsize = (10,20))\n",
    "# ax = ax.flatten()\n",
    "# for idx, im_id in enumerate(top_ims[clu_labs_rm_outliers_order]):\n",
    "#     im = Image.open(paths[im_id])\n",
    "#     ax[idx].imshow(im)\n",
    "#     ax[idx].set_title(f\"{im_id}: cluster {clu_labs_rm_outliers[clu_labs_rm_outliers_order][idx]}\", size = 8)\n",
    "#     ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f10c44",
   "metadata": {},
   "source": [
    "Remove clusters with less than treshold number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d16f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in range(clusterer.n_clusters_):\n",
    "    count = sum(clu_labs_rm_outliers == cluster)\n",
    "    # print(count)\n",
    "    if count < min_ims_cluster: \n",
    "        # print(cluster)\n",
    "        #clu_labs_rm_outliers[i] = clu_labs[i]\n",
    "        clu_labs_rm_outliers[[clu_labs_rm_outliers[i] == cluster for i in range(len(clu_labs_rm_outliers))]] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a7f05",
   "metadata": {},
   "source": [
    "visualise images remaining in clusters after removing small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282521db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_labs_rm_outliers_order = sorted(range(len(clu_labs_rm_outliers)), key=lambda k: clu_labs_rm_outliers[k])\n",
    "\n",
    "fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5, figsize = (10,20))\n",
    "ax = ax.flatten()\n",
    "for idx, im_id in enumerate(top_ims[clu_labs_rm_outliers_order]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    ax[idx].imshow(im)\n",
    "    ax[idx].set_title(f\"{im_id}: cluster {clu_labs_rm_outliers[clu_labs_rm_outliers_order][idx]}\", size = 8)\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defdf321",
   "metadata": {},
   "source": [
    "Plot cosine similarities for all top images and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88321754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cosine_sim = utilities.plot_cosine_similarities(top_ims, min_sim=0, max_sim=1, maps = activations, label = 'all')\n",
    "# cosine_sim = utilities.plot_cosine_similarities(top_ims[clu_labs_rm_outliers_order], min_sim=0, max_sim=1, maps = activations, label = 'ordered')\n",
    "cosine_sim = utilities.plot_cosine_similarities(top_ims[clu_labs_rm_outliers_order][:top-list(clu_labs_rm_outliers).count(100)], min_sim=0, max_sim=1, maps = activations, label = 'ordered')\n",
    "# for cluster in np.unique(clu_labs_rm_outliers):\n",
    "#     if cluster == 100: \n",
    "#         pass\n",
    "#     else:\n",
    "#          cosine_sim = utilities.plot_cosine_similarities(top_ims[clu_labs_rm_outliers==cluster], min_sim=0, max_sim=1, maps = activations, label = f'cluster {round(cluster)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5186537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_matrix = utilities.plot_euclidan_distances(top_activations, 0, 8, label = 'all')\n",
    "# distance_matrix = utilities.plot_euclidan_distances(top_activations[clu_labs_rm_outliers_order], 0, 8, label = 'ordered')\n",
    "distance_matrix = utilities.plot_euclidan_distances(top_activations[clu_labs_rm_outliers_order][:top-list(clu_labs_rm_outliers).count(100)], 0, 8, label = 'ordered')\n",
    "# for cluster in np.unique(clu_labs_rm_outliers):\n",
    "#     if cluster == 100: \n",
    "#         pass\n",
    "#     else:\n",
    "#         distance_matrix = utilities.plot_euclidan_distances(top_activations[clu_labs_rm_outliers==cluster], label = f'cluster {round(cluster)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae773a",
   "metadata": {},
   "source": [
    "plot images: \n",
    "\n",
    "https://stackoverflow.com/questions/22566284/matplotlib-how-to-plot-images-instead-of-points\n",
    "\n",
    "https://matplotlib.org/stable/gallery/text_labels_and_annotations/demo_annotation_box.html\n",
    "\n",
    "add jitter to reduce overlap:\n",
    "\n",
    "https://stackoverflow.com/questions/8671808/matplotlib-avoiding-overlapping-datapoints-in-a-scatter-dot-beeswarm-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dadd61c",
   "metadata": {},
   "source": [
    "Visualise embeddings of images remaining in clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4707a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XY_UMAP = umap.UMAP(n_components=2).fit_transform(top_activations[clu_labs_rm_outliers != 100])\n",
    "amount = 0#.05\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "#ax.set_title(\"UMAP\")\n",
    "ax.scatter(XY_UMAP[:,0], XY_UMAP[:,1]) \n",
    "\n",
    "for x0, y0, path in zip(utilities.rand_jitter(XY_UMAP[:,0], amount), utilities.rand_jitter(XY_UMAP[:,1], amount), [paths[i] for i in top_ims[clu_labs_rm_outliers != 100]]):\n",
    "    ab = AnnotationBbox(utilities.getImage(path), (x0, y0), frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "#ax.axis('off') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68306edf",
   "metadata": {},
   "source": [
    "Plot normalised concepts (removed as same plot below..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cluster in np.unique(clu_labs_rm_outliers):\n",
    "#     if cluster == 100: \n",
    "#         pass\n",
    "#     else:\n",
    "#         plt.plot(top_activations[clu_labs_rm_outliers==cluster].mean(0)/np.linalg.norm(top_activations[clu_labs_rm_outliers==cluster].mean(0)))\n",
    "#         plt.show()\n",
    "#         print(f\"Concept vector {round(cluster)}, direction {direction} activation: \", top_activations[clu_labs_rm_outliers==cluster].mean(0)[direction])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26397f8",
   "metadata": {},
   "source": [
    "## Step 4: Calculate concept vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cfec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_vecs = []\n",
    "for cluster in np.unique(clu_labs_rm_outliers):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        concept_vecs.append(top_activations[clu_labs_rm_outliers==cluster].mean(0)/np.linalg.norm(top_activations[clu_labs_rm_outliers==cluster].mean(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a4e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(concept_vecs)): \n",
    "    # print(\"cosine similarity: \", np.dot(concept_vecs[i], \n",
    "    concepts_dot = np.empty([len(concept_vecs),len(concept_vecs)])\n",
    "    concepts_sim = np.empty([len(concept_vecs),len(concept_vecs)])\n",
    "    for i in range(len(concept_vecs)):\n",
    "        for j in range(len(concept_vecs)):\n",
    "            concepts_dot[i,j] = np.dot(concept_vecs[i], concept_vecs[j])\n",
    "            # same thing as concepts normalised length 1 \n",
    "            concepts_sim[i,j] = concepts_dot[i,j]/(np.linalg.norm(concept_vecs[i])*np.linalg.norm(concept_vecs[j])) \n",
    "# print(concepts_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df95cd",
   "metadata": {},
   "source": [
    "### Analysis of concept vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, cluster in enumerate(np.unique(clu_labs_rm_outliers)):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(concept_vecs[idx])\n",
    "        plt.show()\n",
    "        print(f\"Concept vector {round(cluster)}, direction {direction} activation: \", top_activations[clu_labs_rm_outliers==cluster].mean(0)[direction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362cdc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(concepts_sim)\n",
    "ax = plt.subplot()\n",
    "im = ax.imshow(concepts_sim, cmap='viridis', interpolation='nearest', vmin=0, vmax=1) \n",
    "plt.title(f\"Concept vector cosine similarities\")\n",
    "plt.subplots_adjust(right=0.8)\n",
    "cbar_ax = plt.axes([0.85, 0.1, 0.075, 0.8])\n",
    "plt.colorbar(mappable=(im), cax=cbar_ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a0f60",
   "metadata": {},
   "source": [
    "Projection of top activating direction images on concept vectors vs vanilla direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0a55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in np.unique(clu_labs_rm_outliers):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        concept_vec = top_activations[clu_labs_rm_outliers==cluster].mean(0)/np.linalg.norm(top_activations[clu_labs_rm_outliers==cluster].mean(0))\n",
    "        cluster_vecs = top_activations[clu_labs_rm_outliers==cluster]\n",
    "        concept_dot = [np.dot(concept_vec, cluster_vecs[i]) for i in range(cluster_vecs.shape[0])]\n",
    "        #print(\"\\nconcept_dot - projections along concept: \",concept_dot)\n",
    "        concept_sim = [concept_dot[i]/np.linalg.norm(cluster_vecs[i]) for i in range(cluster_vecs.shape[0])]\n",
    "        #print(\"\\nconcept_sim - cosine similarity with concept: \",concept_sim)\n",
    "\n",
    "        direction_dot = cluster_vecs[:,direction]\n",
    "        #print(\"\\ndirection_dot - projections along direction: \", direction_dot)\n",
    "        direction_sim = [direction_dot[i]/np.linalg.norm(cluster_vecs[i]) for i in range(cluster_vecs.shape[0])]\n",
    "        #print(\"\\ndirection_sim - cosine similarity with direction: \",direction_sim)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(2*2, 2 * 1))\n",
    "        axs[0].set_title(f\"projection\", fontsize=10)\n",
    "        axs[0].tick_params(axis='both', which='major', labelsize=8)\n",
    "        axs[0].tick_params(axis='both', which='minor', labelsize=8)\n",
    "        sns.boxplot((concept_dot, direction_dot),ax = axs[0])\n",
    "        axs[1].set_title(f\"cosine similarity\", fontsize=10)\n",
    "        axs[1].tick_params(axis='both', which='major', labelsize=8)\n",
    "        axs[1].tick_params(axis='both', which='minor', labelsize=8)\n",
    "        sns.boxplot((concept_sim, direction_sim),ax = axs[1])\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af16b8",
   "metadata": {},
   "source": [
    "### Maximally projecting images along concept directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ce561",
   "metadata": {},
   "source": [
    "Find images with largest projection along concept direction. This is effecttively finding the maximally activating images for these directions. \n",
    "\n",
    "Check these directions are clean, monosemantic regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efeb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_ims_dot = np.empty([len(conv_maps_avg),len(concept_vecs)])\n",
    "concepts_ims_sim = np.empty([len(conv_maps_avg),len(concept_vecs)])\n",
    "for i in range(len(conv_maps_avg)):\n",
    "    for concept_id in range(len(concept_vecs)):\n",
    "        concepts_ims_dot[i,concept_id] = np.dot(conv_maps_avg[i], concept_vecs[concept_id])\n",
    "        concepts_ims_sim[i,concept_id] = concepts_ims_dot[i,concept_id]/(np.linalg.norm(conv_maps_avg[i])*np.linalg.norm(conv_maps_avg[concept_id]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_projs = []\n",
    "for concept in range(len(concepts_ims_dot[0,])):\n",
    "    top_projs.append(concepts_ims_dot[:,concept].argsort()[-top:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab94906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_projs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in range(len(concept_vecs)):\n",
    "    fig, ax = plt.subplots(math.ceil(top//5), 5, figsize = (10,20))\n",
    "    ax = ax.flatten()\n",
    "    for idx, im_id in enumerate(top_projs[concept]):# enumerate(concepts_dot[:,concept].argsort()[-top:][::-1]):\n",
    "        im = Image.open(paths[im_id])\n",
    "        ax[idx].imshow(im)\n",
    "        ax[idx].set_title(f\"{im_id}\", size = 8)\n",
    "        ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccbd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compared to the original top activating images for the direction:\n",
    "# print(top_ims)\n",
    "# top_ims = utilities.get_activations(activations_avg = activations, direction = direction).argsort()[-top:][::-1] \n",
    "# for i in range(50):\n",
    "#         im = Image.open(paths[top_ims[i]])\n",
    "#         plt.imshow(im)\n",
    "#         plt.axis('off')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e8aee",
   "metadata": {},
   "source": [
    "## Introducing concept sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0507dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_vecs_th = copy.deepcopy(concept_vecs)\n",
    "for concept in range(len(concept_vecs_th)):\n",
    "    l_th = concept_vecs_th[concept]<threshold\n",
    "    concept_vecs_th[concept][l_th] = 0\n",
    "    concept_vecs_th[concept] = concept_vecs_th[concept]/np.linalg.norm(concept_vecs_th[concept])\n",
    "\n",
    "#plt.plot(concept_vecs[0][concept_vecs[0]>0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de89459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(concept_vecs)): \n",
    "    # print(\"cosine similarity: \", np.dot(concept_vecs[i], \n",
    "    concepts_dot_th = np.empty([len(concept_vecs_th),len(concept_vecs_th)])\n",
    "    concepts_sim_th = np.empty([len(concept_vecs_th),len(concept_vecs_th)])\n",
    "    for i in range(len(concept_vecs_th)):\n",
    "        for j in range(len(concept_vecs_th)):\n",
    "            concepts_dot_th[i,j] = np.dot(concept_vecs_th[i], concept_vecs_th[j])\n",
    "            # same thing as concepts normalised length 1 \n",
    "            concepts_sim_th[i,j] = concepts_dot_th[i,j]/(np.linalg.norm(concept_vecs_th[i])*np.linalg.norm(concept_vecs_th[j])) \n",
    "# print(concepts_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93356085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, cluster in enumerate(np.unique(clu_labs_rm_outliers)):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        plt.plot(concept_vecs_th[idx])\n",
    "        plt.show()\n",
    "        print(f\"Concept vector {round(cluster)}, direction {direction} activation: \", top_activations[clu_labs_rm_outliers==cluster].mean(0)[direction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(concepts_sim_th)\n",
    "ax = plt.subplot()\n",
    "im = ax.imshow(concepts_sim_th, cmap='viridis', interpolation='nearest', vmin=0, vmax=1) \n",
    "plt.title(f\"Concept vector cosine similarities\")\n",
    "plt.subplots_adjust(right=0.8)\n",
    "cbar_ax = plt.axes([0.85, 0.1, 0.075, 0.8])\n",
    "plt.colorbar(mappable=(im), cax=cbar_ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78216b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_th_dot = np.empty([len(conv_maps_avg),len(concept_vecs_th)])\n",
    "concepts_th_sim = np.empty([len(conv_maps_avg),len(concept_vecs_th)])\n",
    "for i in range(len(conv_maps_avg)):\n",
    "    for concept_id in range(len(concept_vecs_th)):\n",
    "        concepts_th_dot[i,concept_id] = np.dot(conv_maps_avg[i], concept_vecs_th[concept_id])\n",
    "        concepts_th_sim[i,concept_id] = concepts_th_dot[i,concept_id]/(np.linalg.norm(conv_maps_avg[i])*np.linalg.norm(conv_maps_avg[concept_id]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_projs_th = []\n",
    "for concept in range(len(concepts_th_dot[0,])):\n",
    "    top_projs_th.append(concepts_th_dot[:,concept].argsort()[-top:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in range(len(concept_vecs_th)):\n",
    "    fig, ax = plt.subplots(math.ceil(top//5), 5, figsize = (10,20))\n",
    "    ax = ax.flatten() \n",
    "    for idx, im_id in enumerate(top_projs_th[concept]):# enumerate(concepts_dot[:,concept].argsort()[-top:][::-1]):\n",
    "        im = Image.open(paths[im_id])\n",
    "        ax[idx].imshow(im)\n",
    "        ax[idx].set_title(f\"{im_id}\", size = 8)\n",
    "        ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f35dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(concept_vecs)): \n",
    "#     # print(\"cosine similarity: \", np.dot(concept_vecs[i], \n",
    "#     concepts_dot = np.empty([len(concept_vecs),len(concept_vecs)])\n",
    "#     concepts_sim = np.empty([len(concept_vecs),len(concept_vecs)])\n",
    "#     for i in range(len(concept_vecs)):\n",
    "#         for j in range(len(concept_vecs)):\n",
    "#             concepts_dot[i,j] = np.dot(concept_vecs[i], concept_vecs[j])\n",
    "#             # same thing as concepts normalised length 1 \n",
    "#             concepts_sim[i,j] = concepts_dot[i,j]/(np.linalg.norm(concept_vecs[i])*np.linalg.norm(concept_vecs[j])) \n",
    "# # print(concepts_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in np.unique(clu_labs_rm_outliers):\n",
    "    i=0\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        concept_vec = concept_vecs_th[i]\n",
    "        cluster_vecs = top_activations[clu_labs_rm_outliers==cluster]\n",
    "        concept_dot = [np.dot(concept_vec, cluster_vecs[i]) for i in range(cluster_vecs.shape[0])]\n",
    "        #print(\"\\nconcept_dot - projections along concept: \",concept_dot)\n",
    "        concept_sim = [concept_dot[i]/np.linalg.norm(cluster_vecs[i]) for i in range(cluster_vecs.shape[0])]\n",
    "        #print(\"\\nconcept_sim - cosine similarity with concept: \",concept_sim)\n",
    "\n",
    "        direction_dot = cluster_vecs[:,direction]\n",
    "        #print(\"\\ndirection_dot - projections along direction: \", direction_dot)\n",
    "        direction_sim = [direction_dot[i]/np.linalg.norm(cluster_vecs[i]) for i in range(cluster_vecs.shape[0])]\n",
    "        #print(\"\\ndirection_sim - cosine similarity with direction: \",direction_sim)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(2*2, 2 * 1))\n",
    "        axs[0].set_title(f\"projection\", fontsize=10)\n",
    "        axs[0].tick_params(axis='both', which='major', labelsize=8)\n",
    "        axs[0].tick_params(axis='both', which='minor', labelsize=8)\n",
    "        sns.boxplot((concept_dot, direction_dot),ax = axs[0])\n",
    "        axs[1].set_title(f\"cosine similarity\", fontsize=10)\n",
    "        axs[1].tick_params(axis='both', which='major', labelsize=8)\n",
    "        axs[1].tick_params(axis='both', which='minor', labelsize=8)\n",
    "        sns.boxplot((concept_sim, direction_sim),ax = axs[1])\n",
    "        plt.tight_layout()\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d18ebe6",
   "metadata": {},
   "source": [
    "## Human in the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb2c13",
   "metadata": {},
   "source": [
    "Generate 5 images for each cluster for qualitative assessment of concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6db06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count observations in each cluster as we randomly select 5 of these images with a random seed\n",
    "# count is a list of the number of observations to choose from in each cluster\n",
    "random.seed(0)\n",
    "count = []\n",
    "for cluster in np.unique(clu_labs_rm_outliers):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        count_cl = 0\n",
    "        for i in range(len(clu_labs_rm_outliers)):\n",
    "            if clu_labs_rm_outliers[i] == cluster:\n",
    "                count_cl += 1       \n",
    "        count.append(count_cl) \n",
    "        \n",
    "# print 5 images of each concept, save manually and use in study\n",
    "for idx, cluster in enumerate(np.unique(clu_labs_rm_outliers)):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Cluster {round(cluster)} samples: \")\n",
    "        for samples_ in range(5):\n",
    "            if idx == 0: \n",
    "                rand_cl = random.randint(0,count[idx]) \n",
    "            else:\n",
    "                rand_cl = random.randint(sum(count[:idx]), sum(count[:idx+1]))\n",
    "            print(rand_cl)\n",
    "            im_id = top_ims[clu_labs_rm_outliers_order][rand_cl-1]\n",
    "            im = Image.open(paths[im_id])\n",
    "            im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbada893",
   "metadata": {},
   "source": [
    "Generate 5 top projecting images for each concept for qualitative assessment of concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4263583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for concept in range(len(top_projs)):\n",
    "    print(f\"Concept {round(concept)} samples: \")\n",
    "    for samples_ in range(5):\n",
    "        rand_im = random.randint(0,top) \n",
    "        print(rand_im)\n",
    "        im_id = top_projs[concept][rand_im]\n",
    "        im = Image.open(paths[im_id])\n",
    "        im.show()\n",
    "#top_projs[concept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 5 images from each cluster, save manually and use in study\n",
    "for idx, cluster in enumerate(np.unique(clu_labs_rm_outliers)):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Cluster {round(cluster)} samples: \")\n",
    "        for samples_ in range(5):\n",
    "            if idx == 0: \n",
    "                rand_cl = random.randint(0,count[idx]) \n",
    "            else:\n",
    "                rand_cl = random.randint(sum(count[:idx]), sum(count[:idx+1]))\n",
    "            print(rand_cl)\n",
    "            im_id = top_ims[clu_labs_rm_outliers_order][rand_cl-1]\n",
    "            im = Image.open(paths[im_id])\n",
    "            im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c65526",
   "metadata": {},
   "source": [
    "## Feature visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa309832",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip uninstall scripts-inceptionv3\n",
    "#!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb984a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True).state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f55416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True)\n",
    "model.to(device).eval()\n",
    "# tried... \n",
    "# import inceptionv3\n",
    "# imp.reload(inceptionv3) \n",
    "# print(\"model\")\n",
    "# inceptionv3.InceptionV3.Inception5h(pretrained=True)\n",
    "# torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True, progress=True).state_dict()\n",
    "# model = inceptionv3.InceptionV3.Inception5h(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08cd0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lucent.modelzoo.util import get_model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer='Mixed_7b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34855eb7",
   "metadata": {},
   "source": [
    "direction objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_param_f = lambda: param.image(128, batch=6, decorrelate=True)\n",
    "obj = objectives.channel(layer, direction)\n",
    "_ = render.render_vis(model, obj, batch_param_f, show_inline=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ba207",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_param_f = lambda: param.image(128, batch=6, decorrelate=True)\n",
    "obj = objectives.channel(layer, direction) - 0.2 * objectives.diversity(layer)\n",
    "_ = render.render_vis(model, obj, batch_param_f, show_inline=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9fe98",
   "metadata": {},
   "source": [
    "cluster direction objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37565a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for concept in range(len(concept_vecs)):\n",
    "    batch_param_f = lambda: param.image(128, batch=6, decorrelate=True)\n",
    "    obj = objectives.direction(layer, torch.tensor(concept_vecs[i]).to(device)) # round(cluster) \n",
    "    _ = render.render_vis(model, obj, batch_param_f, show_inline=True, verbose=True)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638f8c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for concept in range(len(concept_vecs)):\n",
    "    batch_param_f = lambda: param.image(128, batch=6, decorrelate=True)\n",
    "    obj = objectives.direction(layer, torch.tensor(concept_vecs[i]).to(device)) # round(cluster) \n",
    "    _ = render.render_vis(model, obj, batch_param_f, transforms=[transform.jitter(2)], show_inline=True, verbose=True)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for concept in range(len(concept_vecs)):\n",
    "    batch_param_f = lambda: param.image(128, batch=6, decorrelate=True)\n",
    "    obj = objectives.direction(layer, torch.tensor(concept_vecs[i]).to(device)) - 0.2 * objectives.diversity(layer)\n",
    "    _ = render.render_vis(model, obj, batch_param_f, transforms=[transform.jitter(2)], show_inline=True, verbose=True)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03ed77",
   "metadata": {},
   "source": [
    "### Random analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ddd0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "# clu_labs\n",
    "# print(clu_lab_order)\n",
    "# clu_labs_rm_outliers\n",
    "# clu_labs_rm_outliers_order = sorted(range(len(clu_labs_rm_outliers)), key=lambda k: clu_labs_rm_outliers[k])\n",
    "# print(clu_labs_rm_outliers[clu_labs_rm_outliers_order])\n",
    "# print(clu_labs_rm_outliers_order)\n",
    "# clu_labs_rm_outliers\n",
    "# clu_labs_rm_outliers\n",
    "# clu_labs_rm_outliers[clu_labs_rm_outliers != 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983678f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"clusterer.n_clusters_: \", clusterer.n_clusters_)\n",
    "print(\"clusterer.n_leaves_: \", clusterer.n_leaves_)\n",
    "print(\"clusterer.children_: \", clusterer.children_)\n",
    "print(\"clusterer.distances_: \", clusterer.distances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7a30c",
   "metadata": {},
   "source": [
    " ### RW hierarchial and kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"clusterer_0.distances_\", clusterer_0.distances_)\n",
    "# print(\"y\", y)\n",
    "# format for displaying\n",
    "# y_format = ['{:3f}'.format(clusterer_0.distances_[i] - clusterer_0.distances_[i-1]) if i else '{:3f}'.format(clusterer_0.distances_[i]) for i in range(len(clusterer_0.distances_))]  \n",
    "# print(\"y_format\", y_format)\n",
    "# max(y)\n",
    "# np.argmax(y) # 98\n",
    "# clusterer.children_[np.argmax(y)]\n",
    "# clusterer_0.distances_[np.argmax(y)]\n",
    "# clusterer_0.distances_[np.argmax(y)] - clusterer_0.distances_[np.argmax(y)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5353bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rough\n",
    "# linkage(np.asarray(top_activations), method='ward', metric='euclidean')\n",
    "# linkage_res # (99, 4)\n",
    "# scipy.cluster.hierarchy.cophenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11158c",
   "metadata": {},
   "source": [
    "## Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and empty folders\n",
    "if not os.path.exists(f'{SAVEFOLD}concept_ims_direction_{direction}/'):\n",
    "    os.mkdir(f'{SAVEFOLD}concept_ims_direction_{direction}/')\n",
    "if not os.path.exists(f'{SAVEFOLD}concept_ims_direction_{direction}/top_ims/'):\n",
    "    os.mkdir(f'{SAVEFOLD}concept_ims_direction_{direction}/top_ims')\n",
    "        \n",
    "folder = f'{SAVEFOLD}concept_ims_direction_{direction}/top_ims/'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and empty folders for top images\n",
    "if not os.path.exists(f'{SAVEFOLD}concept_ims_direction_{direction}/'):\n",
    "    os.mkdir(f'{SAVEFOLD}concept_ims_direction_{direction}/')\n",
    "if not os.path.exists(f'{SAVEFOLD}concept_ims_direction_{direction}/top_ims/'):\n",
    "    os.mkdir(f'{SAVEFOLD}concept_ims_direction_{direction}/top_ims')\n",
    "        \n",
    "folder = f'{SAVEFOLD}concept_ims_direction_{direction}/top_ims/'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "        \n",
    "# create and empty folders for concepts and ransom\n",
    "concepts = [f'cluster_{round(i)}' for i in np.unique(clu_labs_rm_outliers)] + [f'random_{round(i)}' for i in np.unique(clu_labs_rm_outliers)]\n",
    "for concept in concepts:\n",
    "    if not os.path.exists(f'{SAVEFOLD}concept_ims_direction_{direction}/{concept}/'):\n",
    "        os.mkdir(f'{SAVEFOLD}concept_ims_direction_{direction}/{concept}/')\n",
    "    folder = f'{SAVEFOLD}concept_ims_direction_{direction}/{concept}/'\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea66a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate folders\n",
    "for cluster in np.unique(clu_labs_rm_outliers):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        top_ims[clu_labs_rm_outliers==cluster]\n",
    "\n",
    "for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    im.save(f\"{SAVEFOLD}concept_ims_direction_{direction}/top_ims/{os.path.basename(os.path.normpath(paths[im_id]))}\")\n",
    "\n",
    "for cluster in np.unique(clu_labs_rm_outliers):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        for idx, im_id in enumerate(top_ims[clu_labs_rm_outliers==cluster]): \n",
    "            im = Image.open(paths[im_id])\n",
    "            im.save(f\"{SAVEFOLD}concept_ims_direction_{direction}/cluster_{round(cluster)}/{os.path.basename(os.path.normpath(paths[im_id]))}\")\n",
    "    \n",
    "# old   \n",
    "# for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "#     if clu_labs[clu_lab_order][idx] == 0:\n",
    "#         im = Image.open(paths[im_id])\n",
    "#         im.save(f\"{SAVEFOLD}concept_ims_direction_{direction}/cluster_0/{os.path.basename(os.path.normpath(paths[im_id]))}\")\n",
    "#     elif clu_labs[clu_lab_order][idx] == 1:\n",
    "#         im = Image.open(paths[im_id])\n",
    "#         im.save(f\"{SAVEFOLD}concept_ims_direction_{direction}/cluster_1/{os.path.basename(os.path.normpath(paths[im_id]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate folders of random images to test concepts against\n",
    "for cluster in np.unique(clu_labs_rm_outliers):\n",
    "    if cluster == 100: \n",
    "        pass\n",
    "    else:\n",
    "        for idx, im_id in enumerate(top_ims[clu_labs_rm_outliers==cluster]): \n",
    "            rand = random.randint(0, len(paths))\n",
    "            im = Image.open(paths[rand])\n",
    "            im.save(f\"{SAVEFOLD}concept_ims_direction_{direction}/random_{round(cluster)}/{os.path.basename(os.path.normpath(paths[rand]))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ff2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "end runnable script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e86e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f8c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d4599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63b1f77a",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59171e4",
   "metadata": {},
   "source": [
    "### kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717979b5",
   "metadata": {},
   "source": [
    "How many clusters for kmeans?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53a2fb",
   "metadata": {},
   "source": [
    "Plot the sum of squared distances from the data points to the centers of the k-Means clusters for various values of k. Use the Elbow method to pick the best value of k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968dac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmax = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = {}\n",
    "for k in range(1,kmax):\n",
    "        kmeans = cluster.KMeans(n_clusters=k, n_init=10, max_iter=1000, \n",
    "                                random_state=1).fit(top_activations)\n",
    "        sse[k] = kmeans.inertia_ \n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        # label = kmeans.labels_\n",
    "        # sil_coeff[k] = silhouette_score(data, label, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34612204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a2898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()), 'o-')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_coeff = {}\n",
    "for k in range(2,kmax):\n",
    "    random.seed(1)\n",
    "    kmeans = cluster.KMeans(n_clusters=k, n_init=10, max_iter=1000,\n",
    "                            random_state=2021).fit(top_activations)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff[k] = silhouette_score(top_activations, label, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f786c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sil_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1287ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(sil_coeff.keys()), list(sil_coeff.values()), \"o-\")\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"Silhouette width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5064e",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37161826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XY_MDS = manifold.MDS(n_components=2).fit_transform(top_activations)\n",
    "plt.scatter(x=XY_MDS[:,0],y=XY_MDS[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95a2f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XY_TSNE = manifold.TSNE(n_components=2,perplexity=10).fit_transform(top_activations)\n",
    "plt.scatter(x=XY_TSNE[:,0],y=XY_TSNE[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50236f3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XY_UMAP = umap.UMAP(n_components=2).fit_transform(top_activations)\n",
    "plt.scatter(x=XY_UMAP[:,0],y=XY_UMAP[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7986712",
   "metadata": {},
   "source": [
    "## RW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38229c2b",
   "metadata": {},
   "source": [
    "### Trying HDBSCAN \n",
    "unsuccessful so far... CLusters either in one cluster, or all outlers usually if allow_single_cluster = True. If you don't allow a single cluster, although it gives multiple clusters, it doesn't cluster the concepts very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c7c9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# HDBSCAN doesn't work for top_activations, UMAP 2D, UMAP 10 D\n",
    "XY_UMAP = umap.UMAP(n_components=3).fit_transform(top_activations) # CHANGE\n",
    "clusterer = hdbscan.HDBSCAN() # allow_single_cluster = True\n",
    "clusterer.fit(XY_UMAP) # top_activations\n",
    "print(clusterer.labels_)\n",
    "utilities.clustering_scatterplot(points=XY_UMAP, \n",
    "                       labels=clusterer.labels_,\n",
    "                       centers=None, \n",
    "                       title='UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d175612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_labs = clusterer.labels_\n",
    "print(clu_labs)\n",
    "clu_lab_order = sorted(range(len(clu_labs)), key=lambda k: clu_labs[k])\n",
    "\n",
    "fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5, figsize = (10,20))\n",
    "ax = ax.flatten()\n",
    "for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    ax[idx].imshow(im)\n",
    "    ax[idx].set_title(f\"{im_id}: cluster {clu_labs[clu_lab_order][idx]}\", size = 8)\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaeebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# distance_matrix = pairwise_distances(top_activations, metric = 'euclidean')\n",
    "# clusterer = hdbscan.HDBSCAN(metric='precomputed', allow_single_cluster = True)\n",
    "# clusterer.fit(distance_matrix)\n",
    "# print(clusterer.labels_)\n",
    "# print(distance_matrix)\n",
    "# print(np.min(distance_matrix[np.nonzero(distance_matrix)]))\n",
    "# utilities.clustering_scatterplot(points=XY_UMAP, \n",
    "#                        labels=clusterer.labels_,\n",
    "#                        centers=None, \n",
    "#                        title='UMAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b1274",
   "metadata": {},
   "source": [
    "### Trying DBSCAN\n",
    "unsuccessful so far... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustered_data_sklearn = DBSCAN(eps=10).fit(top_activations) # , metric = \"cosine\"\n",
    "# print(clustered_data_sklearn.labels_)\n",
    "# clustered_data_sklearn\n",
    "\n",
    "# DBSCAN doesn't work for top_activations, UMAP 2D, UMAP 10D, cosine UMAP 2D, cosine UMAP 10D\n",
    "clusterer = DBSCAN(metric = \"cosine\") \n",
    "clusterer.fit(XY_UMAP) # top_activations\n",
    "print(clusterer.labels_)\n",
    "utilities.clustering_scatterplot(points=XY_UMAP, \n",
    "                       labels=clusterer.labels_,\n",
    "                       centers=None, \n",
    "                       title='UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f89f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_labs = clusterer.labels_\n",
    "print(clu_labs)\n",
    "clu_lab_order = sorted(range(len(clu_labs)), key=lambda k: clu_labs[k])\n",
    "\n",
    "fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5, figsize = (10,20))\n",
    "ax = ax.flatten()\n",
    "for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    ax[idx].imshow(im)\n",
    "    ax[idx].set_title(f\"{im_id}: cluster {clu_labs[clu_lab_order][idx]}\", size = 8)\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519d1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ba4f94a",
   "metadata": {},
   "source": [
    "### Analyse n_clusters clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834effa5",
   "metadata": {},
   "source": [
    "Increased the max_iter to 1000 to allow the algorithm more time to converge. \n",
    "Increased n_init to run the algorithm more times with various random seeds. \n",
    "The final results is then the best output of 100 consecutive runs in terms of inertia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67dfb40",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the cluster centers to the dataset.\n",
    "clustered_data_sklearn = KMeans(n_clusters=n_clusters, n_init=100, max_iter=1000).fit(top_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_centers = np.r_[top_activations,clustered_data_sklearn.cluster_centers_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17466a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e2e92",
   "metadata": {},
   "source": [
    "Apply a manifold-learning technique to project the data set to a 2D space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e40b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply multi-dimensional scaling (MDS) to project both the data and the k-Means cluster centers to a 2D space\n",
    "XYcoordinates = manifold.MDS(n_components=2).fit_transform(data_and_centers)\n",
    "print(\"transformation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a04f40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utilities.clustering_scatterplot(points=XYcoordinates[:-n_clusters,:], \n",
    "                       labels=clustered_data_sklearn.labels_, \n",
    "                       centers=XYcoordinates[-n_clusters:,:], \n",
    "                       title='MDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc421ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE to project both the data and the k-Means cluster centers to a 2D space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XYcoordinates = manifold.TSNE(n_components=2, perplexity=10).fit_transform(data_and_centers)\n",
    "print(\"transformation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efcef15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clustering_scatterplot(points=XYcoordinates[:-n_clusters,:], \n",
    "                       labels=clustered_data_sklearn.labels_,\n",
    "                       centers=XYcoordinates[-n_clusters:,:], \n",
    "                       title='TSNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa885d2",
   "metadata": {},
   "source": [
    "It is unclear exactly where the elbow is here. I will therefore look at the average silhouette width for different numbers of clusters. This gives a measure of how well defined clusters are (points in clusters being more similar and points in different clusters being more different). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367afdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_labs = clustered_data_sklearn.labels_\n",
    "# clu_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191dfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5)\n",
    "# ax = ax.flatten()\n",
    "# for idx, im_id in enumerate(top_ims):\n",
    "#     im = Image.open(paths[im_id])\n",
    "#     ax[idx].imshow(im)\n",
    "#     ax[idx].set_title(f\"{im_id}: cluster {clu_labs[idx]}\", size = 8)\n",
    "#     ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106cf22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_lab_order = sorted(range(len(clustered_data_sklearn.labels_)), key=lambda k: clustered_data_sklearn.labels_[k])\n",
    "# clu_lab_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267faf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(math.ceil(len(top_ims)//5), 5, figsize = (10,20))\n",
    "ax = ax.flatten()\n",
    "for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "    im = Image.open(paths[im_id])\n",
    "    ax[idx].imshow(im)\n",
    "    ax[idx].set_title(f\"{im_id}: cluster {clu_labs[clu_lab_order][idx]}\", size = 8)\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clu_lab_order\n",
    "\n",
    "# clu_labs[clu_lab_order] # array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1], dtype=int32)\n",
    "\n",
    "# for idx, im_id in enumerate(top_ims[clu_lab_order]):\n",
    "#     print(im_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3c1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a531d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070456c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
